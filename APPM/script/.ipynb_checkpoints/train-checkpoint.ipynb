{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e14ff64-edf3-49fb-96af-6deae5540300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.7.0\n",
      "Num GPUs Available:  1\n",
      "Test set is  A0101\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import math, os, time, sys, re, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from scipy import stats\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "#testset = 'A0202'\n",
    "#INPUTS: python DLMHC.py 0 A0202\n",
    "#testset = sys.argv[2] # e.g. takes A0202 as input allele name\n",
    "testset = \"A0101\"\n",
    "\n",
    "print(\"Test set is \", testset)\n",
    "runindx = 0 \n",
    "\n",
    "###all the possible sequence letters\n",
    "allSequences = 'ACEDGFIHKMLNQPSRTWVYZ'\n",
    "# Establish a mapping from letters to integers\n",
    "char2int = dict((c, i) for i, c in enumerate(allSequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9f78aee-9908-476e-86c3-5c2effea81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_onehot(datafile):   #build testing matrix\n",
    "    ### READ in test dataset\n",
    "    \"\"\" Reads the test data file and extracts allele subtype,\n",
    "            peptide length, and measurement type. Returns these information\n",
    "            along with the peptide sequence and target values.\n",
    "    \"\"\"\n",
    "    #train数据载入\n",
    "    import os\n",
    "    traindata = os.path.join(\"./../DATA\", \"train_data\", datafile )\n",
    "    print(\"traindata name: \", traindata)\n",
    "    df_train = pd.read_csv(traindata, header=0)\n",
    "    df_train = df_train[df_train.Peptide.str.contains('X') == False]\n",
    "    df_train = df_train[df_train.Peptide.str.contains('B') == False]\n",
    "    df_train = df_train[df_train.Peptide.str.contains('U') == False]\n",
    "    #eg.df_train = pd.read_csv('./DATA/train_data/A0202',sep=\"\\t\")\n",
    "    \n",
    "    #下采样\n",
    "    new_df_0 = df_train.loc[df_train['BindingCategory']== 0].sample(frac = 1)\n",
    "    #上采样\n",
    "    df_1_list = []\n",
    "    for i in range(4):\n",
    "        df_1_list.append(df_train.loc[df_train['BindingCategory']== 1])\n",
    "        new_df_1 = pd.concat(df_1_list)\n",
    "    new_df_train = pd.concat([new_df_0,new_df_1])\n",
    "    new_df_train = new_df_train.sample(frac = 1.0) #shuffle\n",
    "\n",
    "\n",
    "    #X_train--补齐11mer--one_hot_matrix\n",
    "    train_data=transformEL(new_df_train)\n",
    "    trainMatrix = np.empty((0, 11,len(allSequences)), int)      \n",
    "    for num in range(len(train_data.Peptide)):\n",
    "        if num%1000 == 0:\n",
    "            print(train_data.Peptide.iloc[num],num)\n",
    "        trainMatrix = np.append(trainMatrix, [Pept_OneHotMap(train_data.Peptide.iloc[num])], axis=0)\n",
    "    allele_name = train_data['HLA'][0]\n",
    "    assert (trainMatrix.shape[0] == train_data.shape[0])\n",
    "\n",
    "    #test数据载入\n",
    "    testdata = os.path.join(\"./../DATA\", \"test_data\", datafile )\n",
    "    df_test = pd.read_csv(testdata, header=0)\n",
    "    df_test = df_test[df_test.Peptide.str.contains('X') == False]\n",
    "    df_test = df_test[df_test.Peptide.str.contains('B') == False]\n",
    "    df_test = df_test[df_test.Peptide.str.contains('U') == False]\n",
    "    #eg.df_test = pd.read_csv('./DATA/test_data/A0202',sep=\"\\t\")\n",
    "\n",
    "    #X_test--补齐11mer--one_hot_matrix\n",
    "    test_data=transformEL(df_test)\n",
    "    testMatrix = np.empty((0, 11,len(allSequences)), int)      \n",
    "    for num in range(len(test_data.Peptide)):\n",
    "        if num%1000 == 0:\n",
    "            print(test_data.Peptide.iloc[num],num)\n",
    "        testMatrix = np.append(testMatrix, [Pept_OneHotMap(test_data.Peptide.iloc[num])], axis=0)\n",
    "    assert (testMatrix.shape[0] == test_data.shape[0])\n",
    "\n",
    "    Y_train = train_data.BindingCategory\n",
    "    Y_test = test_data.BindingCategory \n",
    "    #\n",
    "    Y_train = Y_train.reset_index(drop=True)\n",
    "    Y_test = Y_test.reset_index(drop=True)\n",
    "    #\n",
    "    trainlen = len(trainMatrix)\n",
    "    ss1 = list(range(trainlen))\n",
    "    rnd.shuffle(ss1)    #\n",
    "    \n",
    "    # combine training and test datasets\n",
    "    datasets={}\n",
    "    datasets['X_train'] = trainMatrix\n",
    "    datasets['Y_train'] = Y_train.values #traindata.BindingCategory.as_matrix()\n",
    "    datasets['X_test'] = testMatrix\n",
    "    datasets['Y_test'] = Y_test.values    \n",
    "\n",
    "    return datasets\n",
    "\n",
    "def Pept_OneHotMap(peptideSeq):\n",
    "    \"\"\" maps amino acid into its numerical index\n",
    "    USAGE\n",
    "    Pept_OneHotMap('A')\n",
    "    array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "    \"\"\"\n",
    "    # integer encode input data\n",
    "    integer_encoded=[char2int[char] for char in peptideSeq]\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "    \tletter = [0 for _ in range(len(allSequences))]\n",
    "    \tletter[value] = 1\n",
    "    \tonehot_encoded.append(letter)\n",
    "    return np.asarray(onehot_encoded)\n",
    "\n",
    "def transformEL(dataset):\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    peptide=dataset.Peptide\n",
    "    peptide2list=peptide.tolist()\n",
    "    for i in range(len(peptide)):\n",
    "        if len(peptide2list[i]) < 11:\n",
    "            n1 = len(peptide2list[i]) // 2\n",
    "            n2 = 11 - len(peptide2list[i])\n",
    "            peptide2list[i] = peptide2list[i][:n1] + 'Z'*n2 + peptide2list[i][n1:]     #将小于11个氨基酸的peptide在中间插空补齐\n",
    "        else:\n",
    "            peptide2list[i] = peptide2list[i][:11]\n",
    "\n",
    "    del dataset['Peptide']\n",
    "    peptides = pd.DataFrame(peptide2list,columns=['Peptide'])\n",
    "    dataset.insert(0,'Peptide',peptides.pop('Peptide'))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64548298-9183-41a6-bb0c-9e9fb609a0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindata name:  ./../DATA/train_data/A0101\n",
      "ASDLZZSQPDL 0\n",
      "KQTWZZETCYA 1000\n",
      "KPAPZZSGLPS 2000\n",
      "AVSIDZVTQGD 3000\n",
      "RDASZZRLEPS 4000\n",
      "LVDDSZEDPGA 5000\n",
      "WPTMZZENLLQ 6000\n",
      "IANAZZISVVS 7000\n",
      "PPIGDVEYLTA 8000\n",
      "MLHEZZLDGLI 9000\n",
      "IADSNZYNWFY 10000\n",
      "FCFGSSKQRAF 11000\n",
      "LRDQZZAAALA 12000\n",
      "ILDEZZRHDNY 13000\n",
      "VSVGIZKCDAR 14000\n",
      "YTTGZZHWDNY 15000\n",
      "IADSNZYNWFY 16000\n",
      "GLYFZZERRRP 17000\n",
      "LQQPWZDPQMP 18000\n",
      "SPPQPZPNDHS 19000\n",
      "DIPRELIGKPL 20000\n",
      "MPRAQSYPDNH 21000\n",
      "RWELEZRLEEE 22000\n",
      "KSDGZZSFIGY 23000\n",
      "GLDLSQAAART 24000\n",
      "YLGGKZQYKCD 25000\n",
      "ISDAAQLPHDY 26000\n",
      "VGPVZZPPKPK 27000\n",
      "PNPSRZSPCLP 28000\n",
      "SVDHRZGTWNG 29000\n",
      "TIKVEZKPTMQ 30000\n",
      "YFGGEARCDAE 31000\n",
      "STNGNYDGVLY 32000\n",
      "ETNLVZGSDKY 33000\n",
      "ILLQZZHEATP 34000\n",
      "ETEESZNLNMY 35000\n",
      "SLVPPAAGSKQ 36000\n",
      "GSGLYZDADSE 37000\n",
      "ATEQAZPLWAY 38000\n",
      "VFKVAELSGNR 39000\n",
      "ISKIZZESEAF 40000\n",
      "PGKPGZYGSPG 41000\n",
      "LWLVSPLLEVQ 42000\n",
      "QYGEZZVANLL 43000\n",
      "IGLNMZLFGPK 44000\n",
      "SEFPFVSLKEP 45000\n",
      "PVPGPZNGTIL 46000\n",
      "DFGNZZSPLHR 47000\n",
      "PDKTVIEYEYD 48000\n",
      "FIDRDGPLFRY 49000\n",
      "NRGDRPPPPVL 50000\n",
      "KVSNVZEGILA 51000\n",
      "IYRCFASNKLG 52000\n",
      "VKMGZZERVRI 53000\n",
      "TTEIZZETLLL 0\n",
      "QMVEILTEENR 1000\n",
      "FKKGKZRYFYF 2000\n",
      "KPRTHZLLCMT 3000\n",
      "RNSQAZHRNFL 4000\n",
      "MLGAGZGVGKS 5000\n",
      "EALPZZFAMAS 6000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rnd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5035/2797831260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetdata_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5035/607276233.py\u001b[0m in \u001b[0;36mgetdata_onehot\u001b[0;34m(datafile)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mtrainlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss1\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# combine training and test datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rnd' is not defined"
     ]
    }
   ],
   "source": [
    "data=getdata_onehot(datafile=testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca782c12-b39d-4ac6-95db-738bf251b398",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26913/677450282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "def binary2onehot(yy):\n",
    "    yy2= np.zeros((len(yy),2), dtype=int) #yy2.shape #(10547, 2)\n",
    "    for num in range(len(yy)):\n",
    "        if yy[num]==1:\n",
    "            yy2[num,0]=1\n",
    "        else:\n",
    "            yy2[num,1]=1\n",
    "    return yy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e157b-63b0-4cf2-a529-32a74b0042e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_ = np.arange(len(data['Y_train']))\n",
    "np.random.shuffle(shuffle_)\n",
    "data['Y_train']=data['Y_train'][shuffle_]\n",
    "data['X_train']=data['X_train'][shuffle_]\n",
    "\n",
    "print(\"X_Train size \", data['X_train'].shape)\n",
    "print(\"Y_Train size \", data['Y_train'].shape)\n",
    "print(\"Train data value=1 \", np.sum(data['Y_train']==1))\n",
    "print(\"X_Test size \" , data['X_test'].shape)\n",
    "print(\"Y_Test size \" , data['Y_test'].shape)\n",
    "print(\"Test data value=1 \", np.sum(data['Y_test']==1))\n",
    "\n",
    "\n",
    "Y_train_labels = data_process.binary2onehot(data['Y_train']) # binary output converted into two classes\n",
    "Y_test_labels = data_process.binary2onehot(data['Y_test'])\n",
    "X_train_data = data['X_train']  #already one hot encoded\n",
    "X_test_data = data['X_test']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
