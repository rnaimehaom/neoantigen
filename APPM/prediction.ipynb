{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49272fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math, os, time, sys, datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from scipy import stats\n",
    "# python script/prediction.py  A0101\n",
    "\n",
    "allSequences = 'ACEDGFIHKMLNQPSRTWVYZ'\n",
    "# Establish a mapping from letters to integers\n",
    "char2int = dict((c, i) for i, c in enumerate(allSequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e502fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "def Pept_OneHotMap(peptideSeq):\n",
    "    \"\"\" maps amino acid into its numerical index\n",
    "    USAGE\n",
    "    Pept_OneHotMap('A')\n",
    "    array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "    \"\"\"\n",
    "    # integer encode input data\n",
    "    integer_encoded=[char2int[char] for char in peptideSeq]\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "    \tletter = [0 for _ in range(len(allSequences))]\n",
    "    \tletter[value] = 1\n",
    "    \tonehot_encoded.append(letter)\n",
    "    return np.asarray(onehot_encoded)\n",
    "###################################################################\n",
    "\n",
    "def transformEL(dataset):\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    peptide=dataset.Peptide\n",
    "    peptide2list=peptide.tolist()\n",
    "\n",
    "    for i in range(len(peptide)):\n",
    "        if len(peptide2list[i]) < 11:\n",
    "            n1 = len(peptide2list[i]) // 2\n",
    "            n2 = 11 - len(peptide2list[i])\n",
    "            peptide2list[i] = peptide2list[i][:n1] + 'Z'*n2 + peptide2list[i][n1:]\n",
    "        else:\n",
    "            peptide2list[i] = peptide2list[i][:11]\n",
    "\n",
    "    del dataset['Peptide']\n",
    "    peptides = pd.DataFrame(peptide2list,columns=['Peptide'])\n",
    "    dataset.insert(0,'Peptide',peptides.pop('Peptide'))\n",
    "    return dataset\n",
    "#####################################################################\n",
    "\n",
    "def getdata_onehot(predictdatafile):\n",
    "    ### READ in test dataset\n",
    "    \"\"\" Reads the test data file and extracts allele subtype,\n",
    "            peptide length, and measurement type. Returns these information\n",
    "            along with the peptide sequence and target values.\n",
    "    \"\"\"\n",
    "    print(\"Test peptide name: \", predictdatafile)\n",
    "    import os\n",
    "    predict_set = os.path.join(\"./DATA\", \"predict_data\", predictdatafile )\n",
    "    print(\"test_set name: \", predict_set)          #sys.argv[1]:A0101\n",
    "    predict_data = pd.read_csv(predict_set, header=0)\n",
    "    predict_data = predict_data[predict_data.Peptide.str.contains('X') == False]\n",
    "    predict_data = predict_data[predict_data.Peptide.str.contains('B') == False]\n",
    "    predict_data = predict_data[predict_data.Peptide.str.contains('U') == False]\n",
    "    #predict_data = pd.read_csv('./DATA/predict_data/A0101',sep=\"\\t\")\n",
    "    \n",
    "    predictdata = pd.DataFrame()\n",
    "    predictdata=transformEL(predict_data)\n",
    "    predictMatrix = np.empty((0, 11,len(allSequences)), int)      #测试集\n",
    "    for num in range(len(predictdata.Peptide)):\n",
    "        if num%1000 == 0:\n",
    "            print(predictdata.Peptide.iloc[num],num)\n",
    "        predictMatrix = np.append(predictMatrix, [Pept_OneHotMap(predictdata.Peptide.iloc[num])], axis=0)\n",
    "\n",
    "\n",
    "    datasets={}\n",
    "    datasets['X_predict'] = predictMatrix   \n",
    "    return datasets\n",
    "###################################################################\n",
    "def conv2d_layer(input_data, num_input_channels, num_filters, filter_shape,strides_, name):   #(x, W, b, strides_=[2,2]):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    # setup the filter input shape for tf.nn.conv_2d\n",
    "    conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels, num_filters]\n",
    "    # initialise weights and bias for the filter\n",
    "    weights = tf.Variable(tf.random.truncated_normal(conv_filt_shape, stddev=0.01), name=name+'_W') #, seed=myseed[2]\n",
    "    bias = tf.Variable(tf.random.truncated_normal([num_filters]), name=name+'_b')  #, seed=myseed[3],\n",
    "    # setup the convolutional layer operation\n",
    "    out_layer = tf.nn.conv2d(input=input_data, filter=weights, strides=[1, strides_[0], strides_[1], 1], padding='SAME')  #see below, Exp1, for the explanations of conv2d if needed.\n",
    "    # add the bias\n",
    "    out_layer = tf.nn.bias_add(out_layer, bias)\n",
    "    # apply a ReLU non-linear activation (or change as you like)\n",
    "    return tf.nn.leaky_relu(features=out_layer, alpha=0.2)\n",
    "\n",
    "def DL_model(inputData):\n",
    "    # add a custom 2D Convolution Layer\n",
    "    #output1a has different filter shape\n",
    "    nfilters1a=128 #can be 512\n",
    "    output1a= conv2d_layer(input_data=inputData , num_input_channels=numofinput_channels,\n",
    "                num_filters=nfilters1a, filter_shape=[2,2],strides_=[1,1], name='CNN2d_1_a')\n",
    "    print(\"CNN2d_1_a output shape: \", output1a.get_shape())\n",
    "    nfilters2a=128\n",
    "    output1a= conv2d_layer(input_data=output1a , num_input_channels=nfilters1a,\n",
    "                num_filters=nfilters2a, filter_shape=[2,2],strides_=[2,2], name='CNN2d_2_a')\n",
    "    print(\"CNN2d_2_a output shape: \", output1a.get_shape())\n",
    "    #**\n",
    "    nfilters3a=256\n",
    "    output1a= conv2d_layer(input_data=output1a , num_input_channels=nfilters2a,\n",
    "                num_filters=nfilters3a, filter_shape=[2,2],strides_=[2,2], name='CNN2d_3_a')\n",
    "    print(\"CNN2d_3_a output shape: \", output1a.get_shape())\n",
    "    nfilters4a=256\n",
    "    output1a= conv2d_layer(input_data=output1a , num_input_channels=nfilters3a,\n",
    "                num_filters=nfilters4a, filter_shape=[2,2],strides_=[2,2], name='CNN2d_4_a')\n",
    "    print(\"CNN2d_4_a output shape: \", output1a.get_shape())\n",
    "    nfilters5a=256\n",
    "    output1a= conv2d_layer(input_data=output1a , num_input_channels=nfilters4a,\n",
    "                num_filters=nfilters5a, filter_shape=[2,2],strides_=[2,2], name='CNN2d_5_a')\n",
    "    print(\"CNN2d_5_a output shape: \", output1a.get_shape())\n",
    "    nfilters6a=512\n",
    "    output1a= conv2d_layer(input_data=output1a , num_input_channels=nfilters5a,\n",
    "                num_filters=nfilters6a, filter_shape=[1,2],strides_=[1,2], name='CNN2d_6_a')\n",
    "    print(\"CNN2d_6_a output shape: \", output1a.get_shape())\n",
    "    nfilters7a=512\n",
    "    output1a= conv2d_layer(input_data=output1a , num_input_channels=nfilters6a,\n",
    "                num_filters=nfilters7a, filter_shape=[1,1],strides_=[1,1], name='CNN2d_7_a')\n",
    "    print(\"CNN2d_7_a output shape: \", output1a.get_shape())\n",
    "    nfilters8a=256\n",
    "    output1a= conv2d_layer(input_data=output1a , num_input_channels=nfilters7a,\n",
    "                num_filters=nfilters8a, filter_shape=[1,1],strides_=[1,1], name='CNN2d_8_a')\n",
    "    print(\"CNN2d_8_a output shape: \", output1a.get_shape())\n",
    "    '''\n",
    "    nfilters9a=256\n",
    "    output1a= conv2d_layer(input_data=output1a , num_input_channels=nfilters8a,\n",
    "                num_filters=nfilters9a, filter_shape=[1,1],strides_=[1,1], name='CNN2d_9_a')\n",
    "    print(\"CNN2d_9_a output shape: \", output1a.get_shape())\n",
    "    '''\n",
    "    #**\n",
    "    lastfiltersize_a=nfilters8a\n",
    "    out1a_h = output1a.get_shape().as_list()[1]; out1a_w  = output1a.get_shape().as_list()[2]\n",
    "    output1a_reshape = tf.reshape(output1a, [-1, out1a_h*out1a_w*lastfiltersize_a])\n",
    "    print(\"CNN2d_1_a output reshaped: \", output1a_reshape.get_shape())\n",
    "    #######layer B: output1b has different filter shape\n",
    "    nfilters1b=128\n",
    "    output1b= conv2d_layer(input_data=inputData , num_input_channels=numofinput_channels,\n",
    "                num_filters=nfilters1b, filter_shape=[1,2],strides_=[1,1], name='CNN2d_1_b')\n",
    "    print(\"CNN2d_1_b output shape: \", output1b.get_shape())\n",
    "    nfilters2b=128\n",
    "    output1b= conv2d_layer(input_data=output1b , num_input_channels=nfilters1b,\n",
    "                num_filters=nfilters2b, filter_shape=[2,2],strides_=[2,2], name='CNN2d_2_b')\n",
    "    print(\"CNN2d_2_b output shape: \", output1b.get_shape())\n",
    "    #**\n",
    "    nfilters3b=256\n",
    "    output1b= conv2d_layer(input_data=output1b , num_input_channels=nfilters2b,\n",
    "                num_filters=nfilters3b, filter_shape=[2,2],strides_=[2,2], name='CNN2d_3_b')\n",
    "    print(\"CNN2d_3_b output shape: \", output1b.get_shape())\n",
    "    nfilters4b=256\n",
    "    output1b= conv2d_layer(input_data=output1b , num_input_channels=nfilters3b,\n",
    "                num_filters=nfilters4b, filter_shape=[2,2],strides_=[2,2], name='CNN2d_4_b')\n",
    "    print(\"CNN2d_4_b output shape: \", output1b.get_shape())\n",
    "    nfilters5b=256\n",
    "    output1b= conv2d_layer(input_data=output1b , num_input_channels=nfilters4b,\n",
    "                num_filters=nfilters5b, filter_shape=[2,2],strides_=[2,2], name='CNN2d_5_b')\n",
    "    print(\"CNN2d_5_b output shape: \", output1b.get_shape())\n",
    "    nfilters6b=512\n",
    "    output1b= conv2d_layer(input_data=output1b , num_input_channels=nfilters5b,\n",
    "                num_filters=nfilters6b, filter_shape=[1,2],strides_=[1,2], name='CNN2d_6_b')\n",
    "    print(\"CNN2d_6_b output shape: \", output1b.get_shape())\n",
    "    nfilters7b=512\n",
    "    output1b= conv2d_layer(input_data=output1b , num_input_channels=nfilters6b,\n",
    "                num_filters=nfilters7b, filter_shape=[1,1],strides_=[1,1], name='CNN2d_7_b')\n",
    "    print(\"CNN2d_7_b output shape: \", output1b.get_shape())\n",
    "    nfilters8b=256\n",
    "    output1b= conv2d_layer(input_data=output1b , num_input_channels=nfilters7b,\n",
    "                num_filters=nfilters8b, filter_shape=[1,1],strides_=[1,1], name='CNN2d_8_b')\n",
    "    print(\"CNN2d_8_b output shape: \", output1b.get_shape())\n",
    "    '''\n",
    "    nfilters9b=128\n",
    "    output1b= conv2d_layer(input_data=output1b , num_input_channels=nfilters8b,\n",
    "                num_filters=nfilters9b, filter_shape=[1,1],strides_=[1,1], name='CNN2d_9_b')\n",
    "    print(\"CNN2d_9_b output shape: \", output1b.get_shape())\n",
    "    '''\n",
    "    #**\n",
    "    lastfiltersize_b=nfilters8b\n",
    "    out1b_h = output1b.get_shape().as_list()[1]; out1b_w  = output1b.get_shape().as_list()[2]\n",
    "    output1b_reshape = tf.reshape(output1b, [-1, out1b_h*out1b_w*lastfiltersize_b])\n",
    "    print(\"CNN2d_1_b output reshaped: \", output1b_reshape.get_shape())\n",
    "    ########\n",
    "    #######layer C: output1c has different filter shape\n",
    "    nfilters1c=128\n",
    "    output1c= conv2d_layer(input_data=inputData , num_input_channels=numofinput_channels,\n",
    "                num_filters=nfilters1c, filter_shape=[2,1],strides_=[1,1], name='CNN2d_1_c')\n",
    "    print(\"CNN2d_1_c output shape: \", output1c.get_shape())\n",
    "    nfilters2c=128\n",
    "    output1c= conv2d_layer(input_data=output1c , num_input_channels=nfilters1c,\n",
    "                num_filters=nfilters2c, filter_shape=[2,2],strides_=[2,2], name='CNN2d_2_c')\n",
    "    print(\"CNN2d_2_c output shape: \", output1c.get_shape())\n",
    "    #**\n",
    "    nfilters3c=256\n",
    "    output1c= conv2d_layer(input_data=output1c , num_input_channels=nfilters2c,\n",
    "                num_filters=nfilters3c, filter_shape=[2,2],strides_=[2,2], name='CNN2d_3_c')\n",
    "    print(\"CNN2d_3_c output shape: \", output1c.get_shape())\n",
    "    nfilters4c=256\n",
    "    output1c= conv2d_layer(input_data=output1c , num_input_channels=nfilters3c,\n",
    "                num_filters=nfilters4c, filter_shape=[2,2],strides_=[2,2], name='CNN2d_4_c')\n",
    "    print(\"CNN2d_4_c output shape: \", output1c.get_shape())\n",
    "    nfilters5c=256\n",
    "    output1c= conv2d_layer(input_data=output1c , num_input_channels=nfilters4c,\n",
    "                num_filters=nfilters5c, filter_shape=[2,2],strides_=[2,2], name='CNN2d_5_c')\n",
    "    print(\"CNN2d_5_c output shape: \", output1c.get_shape())\n",
    "    nfilters6c=512\n",
    "    output1c= conv2d_layer(input_data=output1c , num_input_channels=nfilters5c,\n",
    "                num_filters=nfilters6c, filter_shape=[1,2],strides_=[1,2], name='CNN2d_6_c')\n",
    "    print(\"CNN2d_6_c output shape: \", output1c.get_shape())\n",
    "    nfilters7c=512\n",
    "    output1c= conv2d_layer(input_data=output1c , num_input_channels=nfilters6c,\n",
    "                num_filters=nfilters7c, filter_shape=[1,1],strides_=[1,1], name='CNN2d_7_c')\n",
    "    print(\"CNN2d_7_c output shape: \", output1c.get_shape())\n",
    "    nfilters8c=256\n",
    "    output1c= conv2d_layer(input_data=output1c , num_input_channels=nfilters7c,\n",
    "                num_filters=nfilters8c, filter_shape=[1,1],strides_=[1,1], name='CNN2d_8_c')\n",
    "    print(\"CNN2d_8_c output shape: \", output1c.get_shape())\n",
    "    '''\n",
    "    nfilters9c=256\n",
    "    output1c= conv2d_layer(input_data=output1c , num_input_channels=nfilters8c,\n",
    "                num_filters=nfilters9c, filter_shape=[1,1],strides_=[1,1], name='CNN2d_9_c')\n",
    "    print(\"CNN2d_9_c output shape: \", output1c.get_shape())\n",
    "    '''\n",
    "    #**\n",
    "    lastfiltersize_c=nfilters8c\n",
    "    out1c_h = output1c.get_shape().as_list()[1]; out1c_w  = output1c.get_shape().as_list()[2]\n",
    "    output1c_reshape = tf.reshape(output1c, [-1, out1c_h*out1c_w*lastfiltersize_c])\n",
    "    print(\"CNN2d_1_c output reshaped: \", output1c_reshape.get_shape())\n",
    "    ########\n",
    "\n",
    "    #COMBINE THREE PARALLEL CONV CONNECTIONS OF DIFFERENT FILTER SIZES HERE\n",
    "    flattened = tf.concat([output1a_reshape, output1b_reshape,output1c_reshape], axis=1) #combined the two praralel filters\n",
    "    out_height = flattened.get_shape().as_list()[1]\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output1 to fit fully connected layer input\n",
    "    #flattened = tf.reshape(output1, [-1, out_height * out_width * nfilters2])\n",
    "    print(\"flattened layer output shape: \", flattened.get_shape())\n",
    "    # setup some weights and bias values for this layer, then activate with ReLU\n",
    "    #nnodes_f1 is set at the begining\n",
    "    W_f1 = tf.Variable(tf.random.truncated_normal([out_height, nnodes_f1], stddev=0.01),  name='W_f1') #, seed=myseed[4]\n",
    "    B_f1 = tf.Variable(tf.random.truncated_normal([nnodes_f1], stddev=0.01),  name='B_f1') #, seed=myseed[5]\n",
    "    #\n",
    "    dense_layer1 = tf.add(tf.matmul(flattened, W_f1), B_f1)\n",
    "    dense_layer1 = tf.nn.leaky_relu(features=dense_layer1, alpha=0.2)\n",
    "    print(\"dense_layer1 output shape: \", dense_layer1.get_shape())\n",
    "    #\n",
    "    # Apply Dropout\n",
    "    dense_layer1 = tf.nn.dropout(x=dense_layer1, rate=1-prob_) #Dropout process\n",
    "\n",
    "    # another layer for the final output\n",
    "    wd2 = tf.Variable(tf.random.truncated_normal([nnodes_f1, numofclasses], stddev=0.01), name='wd2') #, seed=myseed[6]\n",
    "    bd2 = tf.Variable(tf.random.truncated_normal([numofclasses], stddev=0.01),  name='bd2') #, seed=myseed[7]\n",
    "    final_layer = tf.add(tf.matmul(dense_layer1, wd2), bd2) #class prediction\n",
    "    print(\"final_layer output shape: \", final_layer.get_shape())\n",
    "    return final_layer\n",
    "###################################################################\n",
    "#将[0,1]变回[0],将[1,0]变回[1]\n",
    "def onehot2binary(yy):\n",
    "    yy2= np.zeros((len(yy),1),dtype=int)\n",
    "    for num in range(len(yy)):\n",
    "        if yy[num][0] > yy[num][1]:\n",
    "            yy2[num] = int(1)\n",
    "        else:\n",
    "            yy2[num] = int(0)\n",
    "    return yy2\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f05945",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numofinput_channels = 1 # 1 data input per feature\n",
    "numofclasses=2  # data labels are binary.\n",
    "#for dropout probability\n",
    "prob_ = tf.compat.v1.placeholder( dtype=tf.float32, shape=() )\n",
    "keep_prob_rate=0.5 #0.4\n",
    "nnodes_f1= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "409e720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.14.0\n",
      "Test set is  A0101\n",
      "Test peptide name:  A0101\n",
      "test_set name:  ./DATA/predict_data/A0101\n",
      "EGWLZZHKRGK 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#载入数据\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "# python script/prediction.py A0101 9mer\n",
    "#alleles = sys.argv[1]   #A0101\n",
    "#input_file = sys.argv[2]   #9mer\n",
    "alleles = \"A0101\"\n",
    "input_file = \"A0101\"\n",
    "print(\"Test set is \", alleles)\n",
    "data = getdata_onehot(predictdatafile=input_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e669438",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = data['X_predict'][0].shape[0] #11, depends onpeptide length\n",
    "input_width = data['X_predict'][0].shape[1]  #21 , comes from size of unique peptide sequence letters\n",
    "# Tensor graph input is 4-D: [Batch Size, Height, Width, Channel]\n",
    "X = tf.compat.v1.placeholder(tf.float32, shape=[None, input_height, input_width])\n",
    "# dynamically reshape the input\n",
    "X_shaped = tf.reshape(X, [-1, input_height, input_width, 1])\n",
    "#None: 'number of' (#) input is dynamic, not decied yet. numofinput_channels is 1 input channel\n",
    "# now declare the output data placeholder - 2 digits\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5cdd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN2d_1_a output shape:  (?, 11, 21, 128)\n",
      "CNN2d_2_a output shape:  (?, 6, 11, 128)\n",
      "CNN2d_3_a output shape:  (?, 3, 6, 256)\n",
      "CNN2d_4_a output shape:  (?, 2, 3, 256)\n",
      "CNN2d_5_a output shape:  (?, 1, 2, 256)\n",
      "CNN2d_6_a output shape:  (?, 1, 1, 512)\n",
      "CNN2d_7_a output shape:  (?, 1, 1, 512)\n",
      "CNN2d_8_a output shape:  (?, 1, 1, 256)\n",
      "CNN2d_1_a output reshaped:  (?, 256)\n",
      "CNN2d_1_b output shape:  (?, 11, 21, 128)\n",
      "CNN2d_2_b output shape:  (?, 6, 11, 128)\n",
      "CNN2d_3_b output shape:  (?, 3, 6, 256)\n",
      "CNN2d_4_b output shape:  (?, 2, 3, 256)\n",
      "CNN2d_5_b output shape:  (?, 1, 2, 256)\n",
      "CNN2d_6_b output shape:  (?, 1, 1, 512)\n",
      "CNN2d_7_b output shape:  (?, 1, 1, 512)\n",
      "CNN2d_8_b output shape:  (?, 1, 1, 256)\n",
      "CNN2d_1_b output reshaped:  (?, 256)\n",
      "CNN2d_1_c output shape:  (?, 11, 21, 128)\n",
      "CNN2d_2_c output shape:  (?, 6, 11, 128)\n",
      "CNN2d_3_c output shape:  (?, 3, 6, 256)\n",
      "CNN2d_4_c output shape:  (?, 2, 3, 256)\n",
      "CNN2d_5_c output shape:  (?, 1, 2, 256)\n",
      "CNN2d_6_c output shape:  (?, 1, 1, 512)\n",
      "CNN2d_7_c output shape:  (?, 1, 1, 512)\n",
      "CNN2d_8_c output shape:  (?, 1, 1, 256)\n",
      "CNN2d_1_c output reshaped:  (?, 256)\n",
      "flattened layer output shape:  (?, 768)\n",
      "dense_layer1 output shape:  (?, 100)\n",
      "final_layer output shape:  (?, 2)\n"
     ]
    }
   ],
   "source": [
    "save_dir = 'checkpoints/' + alleles + '/'\n",
    "save_path = os.path.join(save_dir, 'best_validation')\n",
    "save_thelast_path = os.path.join(save_dir, 'last_weigths')\n",
    "logits = DL_model(inputData=X_shaped)\n",
    "prediction = tf.nn.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a110d477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vicente/anaconda3/envs/tf1-cpu/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/A0101/best_validation\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    #Restore the last saved best model model\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    saver.restore(sess=sess, save_path=save_path)\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    predictions = sess.run(prediction, feed_dict={X: data['X_predict'], prob_: 1.0})\n",
    "    prediction_val = onehot2binary(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc734f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "predict_set = os.path.join(\"./DATA\", \"predict_data\", input_file)         #sys.argv[2]\n",
    "dataset = pd.read_csv(predict_set, header=0)\n",
    "\n",
    "prediction_val = pd.DataFrame(prediction_val,columns=['predictresult'])\n",
    "prediction_ = pd.DataFrame(predictions,columns=['Score','note2'])\n",
    "score = prediction_['Score']\n",
    "#dataset.insert(2,'predictresult',prediction_.pop('predictresult'))\n",
    "result = pd.concat([dataset,prediction_val,score],axis = 1)\n",
    "\n",
    "predict_dir = 'predictresults/' + alleles + '/'\n",
    "if not os.path.exists(predict_dir):\n",
    "    os.makedirs(predict_dir)\n",
    "\n",
    "dataset.to_csv(predict_dir+alleles+'_'+input_file+'.csv',index=False,sep='\\t')\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f07e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
